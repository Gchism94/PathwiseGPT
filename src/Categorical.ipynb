{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hY0CwJgCER_1"
      },
      "outputs": [],
      "source": [
        "import os # Handles file paths and directories\n",
        "import json # Parses and loads JSON files for rules and configurations\n",
        "import unittest # Framework for writing and running unit tests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To load categorical data rules from JSON file\n",
        "with open(\"analysis/data/derivedData/rules_categorical.json\", \"r\") as file:\n",
        "    categorical_data_rules = json.load(file)"
      ],
      "metadata": {
        "id": "D4Nh1TvLTtKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To load configuration file for dataset thresholds\n",
        "with open(\"analysis/data/derivedData/config.json\", \"r\") as config_file:\n",
        "    config = json.load(config_file)\n",
        "\n",
        "SMALL_THRESHOLD = config[\"dataset_thresholds\"][\"small_dataset\"]\n",
        "LARGE_THRESHOLD = config[\"dataset_thresholds\"][\"large_dataset\"]"
      ],
      "metadata": {
        "id": "5TzprQfypXFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_parameters(data_type, task, rules):\n",
        "    \"\"\"\n",
        "    Validates input parameters for logic generation.\n",
        "\n",
        "    Args:\n",
        "        data_type (str): Type of data (e.g., 'Categorical').\n",
        "        task (str): Task type (e.g., 'Classification', 'Clustering').\n",
        "        rules (dict): The rules JSON for the respective data type.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If the task is invalid.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    valid_tasks = rules[\"tasks\"].keys()\n",
        "    if task not in valid_tasks:\n",
        "        raise ValueError(f\"Invalid task: {task}. Choose from {', '.join(valid_tasks)}.\")"
      ],
      "metadata": {
        "id": "l90tNkoogaWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_logic(models, condition=None, dataset_size=None):\n",
        "    \"\"\"\n",
        "    Validates if the models fit the task-specific conditions.\n",
        "\n",
        "    Args:\n",
        "        models (list): List of models retrieved from the rules.\n",
        "        condition (str, optional): Specific condition being validated.\n",
        "        dataset_size (int, optional): Dataset size for validation.\n",
        "\n",
        "    Returns:\n",
        "        bool: True if validation passes, False otherwise.\n",
        "    \"\"\"\n",
        "    if not models:\n",
        "        print(f\"Warning: No models fit the condition '{condition}' for dataset size '{dataset_size}'.\")\n",
        "        return False\n",
        "    return True"
      ],
      "metadata": {
        "id": "dzY5Ze5Qgan_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classification_logic(data, dataset_size):\n",
        "    \"\"\"\n",
        "    Handles logic for classification tasks, incorporating dataset thresholds.\n",
        "\n",
        "    Args:\n",
        "        data (dict): Categorical data rules.\n",
        "        dataset_size (int): Size of the dataset for classification.\n",
        "\n",
        "    Returns:\n",
        "        str: Logic text for classification tasks.\n",
        "    \"\"\"\n",
        "    logic_text = \"If the problem is a classification task:\\n\"\n",
        "    classification_tasks = data[\"tasks\"][\"classification\"]\n",
        "\n",
        "    # To determine dataset size category\n",
        "    if dataset_size < SMALL_THRESHOLD:\n",
        "        size_category = \"small_dataset\"\n",
        "    elif dataset_size > LARGE_THRESHOLD:\n",
        "        size_category = \"large_dataset\"\n",
        "    else:\n",
        "        size_category = \"medium_dataset\"\n",
        "\n",
        "    # Iterating through classification task rules\n",
        "    for condition, sub_conditions in classification_tasks.items():\n",
        "        if condition == size_category:  # Matching dataset size category\n",
        "            logic_text += f\"  If the dataset is categorized as {size_category}:\\n\"\n",
        "        elif condition == \"default\":\n",
        "            logic_text += \"    Else:\\n\"\n",
        "        else:\n",
        "            logic_text += f\"  If the task involves {condition} classification:\\n\"\n",
        "\n",
        "        # Checking sub-conditions and apply models\n",
        "        for sub_condition, models in sub_conditions.items():\n",
        "            if sub_condition == \"default\":\n",
        "                logic_text += \"      Else:\\n\"\n",
        "            else:\n",
        "                logic_text += f\"      If {sub_condition}:\\n\"\n",
        "            for approach, model_list in models.items():\n",
        "                if validate_logic(model_list, sub_condition, dataset_size):\n",
        "                    logic_text += f\"        Use {approach} models: {', '.join(model_list)}\\n\"\n",
        "                else:\n",
        "                    logic_text += f\"        Warning: No suitable models found for {sub_condition}.\\n\"\n",
        "\n",
        "    return logic_text"
      ],
      "metadata": {
        "id": "xSUJG3nN6Rlv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clustering_logic(data):\n",
        "    \"\"\"\n",
        "    Handles logic for clustering tasks.\n",
        "\n",
        "    Args:\n",
        "        data (dict): Categorical data rules.\n",
        "\n",
        "    Returns:\n",
        "        str: Logic text for clustering tasks.\n",
        "    \"\"\"\n",
        "    logic_text = \"If the problem is a clustering task:\\n\"\n",
        "    clustering_tasks = data[\"tasks\"][\"clustering\"]\n",
        "\n",
        "    for condition, models in clustering_tasks.items():\n",
        "        if condition == \"default\":\n",
        "            logic_text += f\"  Else:\\n\"\n",
        "        else:\n",
        "            logic_text += f\"  If the clusters are {condition}:\\n\"\n",
        "        for approach, model_list in models.items():\n",
        "            if validate_logic(model_list, condition):\n",
        "                logic_text += f\"    Use {approach} models: {', '.join(model_list)}\\n\"\n",
        "            else:\n",
        "                logic_text += f\"    Warning: No suitable models found for {condition}.\\n\"\n",
        "\n",
        "    return logic_text"
      ],
      "metadata": {
        "id": "o4QZiBA3GrnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dimensionality_reduction_logic(data):\n",
        "    \"\"\"\n",
        "    Handles logic for dimensionality reduction tasks.\n",
        "\n",
        "    Args:\n",
        "        data (dict): Categorical data rules.\n",
        "\n",
        "    Returns:\n",
        "        str: Logic text for dimensionality reduction tasks.\n",
        "    \"\"\"\n",
        "    logic_text = \"If the problem is dimensionality reduction:\\n\"\n",
        "    dimensionality_tasks = data[\"tasks\"][\"dimensionality_reduction\"]\n",
        "\n",
        "    for condition, models in dimensionality_tasks.items():\n",
        "        if condition == \"default\":\n",
        "            logic_text += f\"  Else:\\n\"\n",
        "        else:\n",
        "            logic_text += f\"  If {condition} is important:\\n\"\n",
        "        for approach, model_list in models.items():\n",
        "            if validate_logic(model_list, condition):\n",
        "                logic_text += f\"    Use {approach} models: {', '.join(model_list)}\\n\"\n",
        "            else:\n",
        "                logic_text += f\"    Warning: No suitable models found for {condition}.\\n\"\n",
        "\n",
        "    return logic_text"
      ],
      "metadata": {
        "id": "ve42jb-LGro5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_categorical_logic(data_type, task, dataset_size=None):\n",
        "    \"\"\"\n",
        "    Generate ML/DL decision logic dynamically for categorical data tasks.\n",
        "\n",
        "    Args:\n",
        "        data_type (str): Type of data (e.g., 'Categorical').\n",
        "        task (str): Task type (e.g., 'Classification', 'Clustering', 'Dimensionality Reduction').\n",
        "        dataset_size (int, optional): Size of the dataset for validation.\n",
        "\n",
        "    Returns:\n",
        "        str: Decision logic text.\n",
        "    \"\"\"\n",
        "    validate_parameters(data_type, task, categorical_data_rules) # To ensure inputs are valid\n",
        "\n",
        "    if task == \"classification\":\n",
        "        return classification_logic(categorical_data_rules, dataset_size)\n",
        "    elif task == \"clustering\":\n",
        "        return clustering_logic(categorical_data_rules)\n",
        "    elif task == \"dimensionality_reduction\":\n",
        "        return dimensionality_reduction_logic(categorical_data_rules)\n",
        "    else:\n",
        "        raise ValueError(f\"Task {task} not supported for data type {data_type}.\")"
      ],
      "metadata": {
        "id": "2cAdKIjWGrq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_categorical_logic(\"Categorical\", \"classification\", dataset_size = 500))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOEfxd7BGrsd",
        "outputId": "3d0f3e67-b57b-4703-bada-9228fdfd4051"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "If the problem is a classification task:\n",
            "  If the task involves binary_classification classification:\n",
            "      If requires_interpretability:\n",
            "        Use ML models: Logistic Regression\n",
            "      If small_dataset:\n",
            "        Use ML models: K-Nearest Neighbors (KNN)\n",
            "      If linear_decision_boundaries:\n",
            "        Use ML models: Support Vector Machines (SVM)\n",
            "      Else:\n",
            "        Use DL models: Feedforward Neural Network\n",
            "  If the task involves multi_class classification:\n",
            "      If high_dimensional:\n",
            "        Use ML models: Support Vector Machines (SVM)\n",
            "      If text_data:\n",
            "        Use ML models: Naive Bayes\n",
            "      If requires_interpretability:\n",
            "        Use ML models: Decision Tree Classifier\n",
            "      Else:\n",
            "        Use ML models: Random Forest Classifier\n",
            "      If large_complex:\n",
            "        Use DL models: Transformer-based Models\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_categorical_logic(\"Categorical\", \"clustering\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLzLQ_CLGruh",
        "outputId": "6cee571b-7ab2-429e-e8da-4c41f07213a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "If the problem is a clustering task:\n",
            "  If the clusters are distinct_clusters:\n",
            "    Use ML models: K-Means Clustering\n",
            "  If the clusters are hierarchical_structure:\n",
            "    Use ML models: Hierarchical Clustering\n",
            "  If the clusters are arbitrary_shapes:\n",
            "    Use ML models: DBSCAN\n",
            "  If the clusters are probabilistic_boundaries:\n",
            "    Use ML models: Gaussian Mixture Models (GMM)\n",
            "  Else:\n",
            "    Use DL models: Autoencoder-based Clustering\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_categorical_logic(\"Categorical\", \"dimensionality_reduction\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjUqHgp_GrwV",
        "outputId": "0c43692c-04b6-43d1-8bbe-8ff81e42c42e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "If the problem is dimensionality reduction:\n",
            "  If maximize_variance is important:\n",
            "    Use ML models: Principal Component Analysis (PCA)\n",
            "  If supervised_class_separation is important:\n",
            "    Use ML models: Linear Discriminant Analysis (LDA)\n",
            "  If local_structure is important:\n",
            "    Use ML models: t-SNE\n",
            "  If local_global_structure is important:\n",
            "    Use ML models: UMAP\n",
            "  Else:\n",
            "    Use ML models: Independent Component Analysis (ICA)\n",
            "    Use DL models: Variational Autoencoders (VAE)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test scenarios for logic validation\n",
        "test_scenarios = [\n",
        "    {\n",
        "        \"data_type\": \"Categorical\",\n",
        "        \"task\": \"classification\",\n",
        "        \"dataset_size\": 500,  # Small dataset\n",
        "        \"expected_model\": \"Logistic Regression\"\n",
        "    },\n",
        "    {\n",
        "        \"data_type\": \"Categorical\",\n",
        "        \"task\": \"classification\",\n",
        "        \"dataset_size\": 5000,  # Medium dataset\n",
        "        \"expected_model\": \"Feedforward Neural Network\"\n",
        "    },\n",
        "    {\n",
        "        \"data_type\": \"Categorical\",\n",
        "        \"task\": \"clustering\",\n",
        "        \"dataset_size\": None,  # Dataset size not required for clustering\n",
        "        \"expected_model\": \"K-Means Clustering\"\n",
        "    },\n",
        "    {\n",
        "        \"data_type\": \"Categorical\",\n",
        "        \"task\": \"dimensionality_reduction\",\n",
        "        \"dataset_size\": None,  # Dataset size not required for dimensionality reduction\n",
        "        \"expected_model\": \"Principal Component Analysis (PCA)\"\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "EhVW2av8GryF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TestCategoricalLogic(unittest.TestCase):\n",
        "    \"\"\"\n",
        "    Unit tests for validating the logic functions for categorical data.\n",
        "    \"\"\"\n",
        "\n",
        "    def test_logic(self):\n",
        "        \"\"\"\n",
        "        Test logic across multiple scenarios.\n",
        "\n",
        "        This test dynamically iterates over predefined scenarios to validate model mapping.\n",
        "        \"\"\"\n",
        "        for scenario in test_scenarios:\n",
        "            with self.subTest(scenario=scenario):\n",
        "                result = generate_categorical_logic(\n",
        "                    data_type=scenario[\"data_type\"],\n",
        "                    task=scenario[\"task\"],\n",
        "                    dataset_size=scenario[\"dataset_size\"]\n",
        "                )\n",
        "                self.assertIn(\n",
        "                    scenario[\"expected_model\"],\n",
        "                    result,\n",
        "                    f\"Failed for {scenario['task']} with dataset size {scenario['dataset_size']}\"\n",
        "                )\n",
        "\n",
        "    def test_invalid_task(self):\n",
        "        \"\"\"\n",
        "        Test behavior for an invalid task.\n",
        "\n",
        "        This test ensures that passing an invalid task raises a ValueError.\n",
        "        \"\"\"\n",
        "        with self.assertRaises(ValueError):\n",
        "            generate_categorical_logic(\"Categorical\", \"invalid_task\")"
      ],
      "metadata": {
        "id": "BpPzVY39Grz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    unittest.main(argv=[''], exit=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlMX-cqujVsc",
        "outputId": "3e24445d-1b48-4e59-90ef-9f44cde7bf8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".\n",
            "----------------------------------------------------------------------\n",
            "Ran 1 test in 0.003s\n",
            "\n",
            "OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TestCategoricalLogic(unittest.TestCase):\n",
        "    \"\"\"\n",
        "    Unit tests for validating the rules for categorical data logic.\n",
        "    \"\"\"\n",
        "\n",
        "    def test_small_dataset_binary_classification(self):\n",
        "        \"\"\"\n",
        "        Test whether a small dataset with binary classification maps to Logistic Regression.\n",
        "\n",
        "        This ensures that the implemented rules correctly map binary classification\n",
        "        with small datasets to Logistic Regression.\n",
        "        \"\"\"\n",
        "        for scenario in test_scenarios:\n",
        "            with self.subTest(scenario=scenario):\n",
        "                # Generate logic using the defined function\n",
        "                result = generate_categorical_logic(\n",
        "                    data_type=scenario[\"data_type\"],\n",
        "                    task=scenario[\"task\"],\n",
        "                    dataset_size=scenario[\"dataset_size\"]\n",
        "                )\n",
        "                # Validate that the expected model is in the result\n",
        "                self.assertIn(\n",
        "                    scenario[\"expected_model\"],\n",
        "                    result,\n",
        "                    f\"Expected model {scenario['expected_model']} not found for binary classification.\"\n",
        "                )\n"
      ],
      "metadata": {
        "id": "Ll44Pln8kSpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    unittest.main(argv=[''], exit=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnuFZ4LKkTF-",
        "outputId": "9e3dcb30-de58-4d2b-cebc-6a19c4cf373a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".\n",
            "----------------------------------------------------------------------\n",
            "Ran 1 test in 0.006s\n",
            "\n",
            "OK\n"
          ]
        }
      ]
    }
  ]
}