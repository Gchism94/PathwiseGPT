{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f2a121-6311-4db1-b9de-70d9c548d06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # Handles file paths and directories\n",
    "import json # Parses and loads JSON files for rules and configurations\n",
    "import unittest # Framework for writing and running unit tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460a6a1c-ec3e-4744-a899-49073d637c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load numerical rules from the JSON file\n",
    "with open(\"analysis/data/derivedData/rules_tabular.json\", \"r\") as file:\n",
    "    numerical_data_rules = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ace30d8-f940-43d5-8cf4-e9069c0708f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load configuration file for dataset size thresholds\n",
    "with open(\"analysis/data/derivedData/config.json\", \"r\") as config_file:\n",
    "    config = json.load(config_file)\n",
    "\n",
    "# Threshold values for small and large datasets\n",
    "SMALL_THRESHOLD = config[\"dataset_thresholds\"][\"small_dataset\"]\n",
    "LARGE_THRESHOLD = config[\"dataset_thresholds\"][\"large_dataset\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "034960ee-c7b5-41e4-a8e5-cbd2ae4d7f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.016s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If the problem is tabular classification:\n",
      "  If small_dataset:\n",
      "    Use ML models: Random Forest, Support Vector Machine (SVM)\n",
      "  If large_dataset:\n",
      "    Use ML models: Gradient Boosting Trees (GBT), XGBoost\n",
      "  Else:\n",
      "    Use DL models: Shallow Fully Connected Networks\n",
      "\n",
      "If the problem is tabular regression:\n",
      "  If small_dataset:\n",
      "    Use ML models: Linear Regression, Gradient Boosting Trees (GBT)\n",
      "  If large_dataset:\n",
      "    Use ML models: Random Forest Regression\n",
      "  Else:\n",
      "    Use DL models: Deeper Fully Connected Networks\n",
      "\n",
      "If the problem is feature importance:\n",
      "  Else:\n",
      "    Use ML models: Decision Trees, Explainable Boosting Machine (EBM)\n",
      "\n",
      "Tabular Classification: ['Gradient Boosting Trees (GBT)', 'XGBoost']\n",
      "Warning: No suitable models found for task 'tabular_classification' with characteristics ['undefined_characteristic'].\n",
      "Tabular Classification (No match): None\n",
      "Warning: No suitable models found for task 'tabular_classification' with characteristics ['unknown_condition'].\n"
     ]
    }
   ],
   "source": [
    "# Validation function for models\n",
    "def validate_logic(models, condition=None):\n",
    "    \"\"\"\n",
    "    Validates if the models fit the condition.\n",
    "\n",
    "    Args:\n",
    "        models (list): List of models retrieved from the rules.\n",
    "        condition (str, optional): Specific condition being validated.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if validation passes, False otherwise.\n",
    "    \"\"\"\n",
    "    if not models:\n",
    "        print(f\"Warning: No models fit the condition '{condition}'.\")\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# Handles logic for flat conditions (no nested structure)\n",
    "def handle_flat_conditions(sub_conditions, indent_level=2):\n",
    "    \"\"\"\n",
    "    Handles flat ML/DL conditions for tabular tasks.\n",
    "    \"\"\"\n",
    "    logic = \"\"\n",
    "    indent = \"  \" * indent_level\n",
    "    for approach, model_list in sub_conditions.items():\n",
    "        logic += f\"{indent}Use {approach} models: {', '.join(model_list)}\\n\"\n",
    "    return logic\n",
    "\n",
    "# Logic generator for tabular tasks\n",
    "def generate_task_logic(data, task_name):\n",
    "    \"\"\"\n",
    "    Handles logic dynamically for tabular data tasks.\n",
    "    \"\"\"\n",
    "    logic_text = f\"If the problem is {task_name.replace('_', ' ')}:\\n\"\n",
    "    task_details = data[\"tasks\"][task_name]\n",
    "\n",
    "    for condition, sub_conditions in task_details.items():\n",
    "        if condition == \"default\":\n",
    "            logic_text += f\"  Else:\\n\"\n",
    "        else:\n",
    "            logic_text += f\"  If {condition}:\\n\"\n",
    "        \n",
    "        logic_text += handle_flat_conditions(sub_conditions, indent_level=2)\n",
    "\n",
    "    return logic_text\n",
    "\n",
    "# Main function for generating tabular data logic\n",
    "def generate_tabular_logic(task):\n",
    "    \"\"\"\n",
    "    Generate ML/DL decision logic dynamically for tabular data tasks.\n",
    "\n",
    "    Args:\n",
    "        task (str): Task type (e.g., 'tabular_classification', 'tabular_regression').\n",
    "\n",
    "    Returns:\n",
    "        str: Decision logic text.\n",
    "    \"\"\"\n",
    "    valid_tasks = tabular_data_rules[\"tasks\"].keys()\n",
    "    if task not in valid_tasks:\n",
    "        raise ValueError(f\"Task '{task}' is not supported. Available tasks: {', '.join(valid_tasks)}\")\n",
    "\n",
    "    return generate_task_logic(tabular_data_rules, task)\n",
    "\n",
    "# Example usage of tabular logic generation\n",
    "print(generate_tabular_logic(\"tabular_classification\"))\n",
    "print(generate_tabular_logic(\"tabular_regression\"))\n",
    "print(generate_tabular_logic(\"feature_importance\"))\n",
    "\n",
    "# Function to validate model choices based on dataset characteristics\n",
    "def validate_model_choice(task_rules, task_name, dataset_characteristics):\n",
    "    \"\"\"\n",
    "    Validate model choices based on dataset characteristics and task rules.\n",
    "    Raises warnings if no model fits the conditions defined in the rules.\n",
    "    \"\"\"\n",
    "    if task_name not in task_rules[\"tasks\"]:\n",
    "        raise ValueError(f\"Task '{task_name}' is not supported.\")\n",
    "\n",
    "    task_details = task_rules[\"tasks\"][task_name]\n",
    "    applicable_models = []\n",
    "\n",
    "    # Check if any condition matches the dataset characteristics\n",
    "    for condition, sub_conditions in task_details.items():\n",
    "        if condition == \"default\":\n",
    "            continue  # Default is handled later\n",
    "\n",
    "        if condition in dataset_characteristics:\n",
    "            applicable_models.extend(\n",
    "                model\n",
    "                for approach in sub_conditions.values()\n",
    "                for model in approach\n",
    "            )\n",
    "\n",
    "    # Return default models only if some valid characteristics exist but no models match\n",
    "    if not applicable_models and \"default\" in task_details:\n",
    "        # Return default models only if characteristics are valid (but no specific matches)\n",
    "        if any(cond in task_details for cond in dataset_characteristics):\n",
    "            applicable_models.extend(\n",
    "                model\n",
    "                for approach in task_details[\"default\"].values()\n",
    "                for model in approach\n",
    "            )\n",
    "\n",
    "    if not applicable_models:\n",
    "        print(f\"Warning: No suitable models found for task '{task_name}' with characteristics {dataset_characteristics}.\")\n",
    "        return None\n",
    "\n",
    "    return applicable_models\n",
    "\n",
    "# Example validation for tabular data rules\n",
    "dataset_characteristics_tabular = [\"large_dataset\"]\n",
    "print(\"Tabular Classification:\", validate_model_choice(tabular_data_rules, \"tabular_classification\", dataset_characteristics_tabular))\n",
    "\n",
    "dataset_characteristics_tabular_empty = [\"undefined_characteristic\"]\n",
    "print(\"Tabular Classification (No match):\", validate_model_choice(tabular_data_rules, \"tabular_classification\", dataset_characteristics_tabular_empty))\n",
    "\n",
    "# Unit tests for tabular data logic\n",
    "class TestTabularLogic(unittest.TestCase):\n",
    "    \"\"\"\n",
    "    Unit tests for the generate_tabular_logic function and model validation.\n",
    "    \"\"\"\n",
    "    def test_tabular_classification_logic(self):\n",
    "        \"\"\"\n",
    "        Test tabular classification logic.\n",
    "        \"\"\"\n",
    "        result = generate_tabular_logic(\"tabular_classification\")\n",
    "        self.assertIn(\"Random Forest\", result, \"Expected 'Random Forest' in tabular classification logic.\")\n",
    "        self.assertIn(\"Shallow Fully Connected Networks\", result, \"Expected 'Shallow Fully Connected Networks' in default logic.\")\n",
    "\n",
    "    def test_tabular_regression_logic(self):\n",
    "        \"\"\"\n",
    "        Test tabular regression logic.\n",
    "        \"\"\"\n",
    "        result = generate_tabular_logic(\"tabular_regression\")\n",
    "        self.assertIn(\"Linear Regression\", result, \"Expected 'Linear Regression' in tabular regression logic.\")\n",
    "\n",
    "    def test_invalid_task(self):\n",
    "        \"\"\"\n",
    "        Test behavior for an invalid task.\n",
    "        \"\"\"\n",
    "        with self.assertRaises(ValueError):\n",
    "            generate_tabular_logic(\"invalid_task\")\n",
    "\n",
    "    def test_model_validation(self):\n",
    "        \"\"\"\n",
    "        Test model validation based on dataset characteristics.\n",
    "        \"\"\"\n",
    "        dataset_characteristics = [\"large_dataset\"]\n",
    "        result = validate_model_choice(tabular_data_rules, \"tabular_classification\", dataset_characteristics)\n",
    "        self.assertIn(\"XGBoost\", result, \"Expected 'XGBoost' in the applicable models for tabular classification.\")\n",
    "\n",
    "    def test_invalid_characteristics(self):\n",
    "        \"\"\"\n",
    "        Test model validation with invalid dataset characteristics.\n",
    "        \"\"\"\n",
    "        dataset_characteristics = [\"unknown_condition\"]\n",
    "        result = validate_model_choice(tabular_data_rules, \"tabular_classification\", dataset_characteristics)\n",
    "        self.assertIsNone(result, \"Expected no models to be found for unknown conditions.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    unittest.main(argv=[''], exit=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d32a62-340e-469e-a233-87401a2db50e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
