{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a6a23c-85a4-4c6d-a805-06ef3cfd1fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # Handles file paths and directories\n",
    "import json # Parses and loads JSON files for rules and configurations\n",
    "import unittest # Framework for writing and running unit tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02feba76-262c-40a5-b07b-63bed55493d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load numerical rules from the JSON file\n",
    "with open(\"analysis/data/derivedData/rules_audio.json\", \"r\") as file:\n",
    "    numerical_data_rules = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb88f90-742b-4ce4-b7b0-91aa8e6945f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load configuration file for dataset size thresholds\n",
    "with open(\"analysis/data/derivedData/config.json\", \"r\") as config_file:\n",
    "    config = json.load(config_file)\n",
    "\n",
    "# Threshold values for small and large datasets\n",
    "SMALL_THRESHOLD = config[\"dataset_thresholds\"][\"small_dataset\"]\n",
    "LARGE_THRESHOLD = config[\"dataset_thresholds\"][\"large_dataset\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2f89543-56ba-4c5f-9bc6-cd39019e6ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.012s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If the problem is audio classification:\n",
      "  If requires_real_time_constraints:\n",
      "    Use DL models: CNN-based Models\n",
      "  If is_proximity_based:\n",
      "    Use ML models: K-Nearest Neighbors (KNN)\n",
      "  If small_dataset:\n",
      "    Use ML models: Support Vector Machine (SVM)\n",
      "  If requires_interpretability:\n",
      "    Use ML models: Decision Trees\n",
      "  If binary_classification:\n",
      "    Use ML models: Logistic Regression\n",
      "  Else:\n",
      "    Use DL models: RNN-based Models\n",
      "\n",
      "If the problem is sequential audio patterns:\n",
      "  If requires_long_term_dependencies:\n",
      "    Use DL models: RNN, LSTM\n",
      "  If requires_real_time_constraints:\n",
      "    Use DL models: Temporal Convolutional Networks (TCN)\n",
      "  Else:\n",
      "    Use ML models: Hidden Markov Models (HMM)\n",
      "\n",
      "If the problem is speech recognition:\n",
      "  If speech_to_text:\n",
      "    Use DL models: CTC with LSTM\n",
      "  If requires_real_time_constraints:\n",
      "    Use DL models: DeepSpeech, Wav2Vec 2.0\n",
      "  Else:\n",
      "    Use DL models: Speech Transformer\n",
      "\n",
      "If the problem is text to speech synthesis:\n",
      "  If requires_real_time_constraints:\n",
      "    Use DL models: Tacotron2, FastSpeech\n",
      "  Else:\n",
      "    Use DL models: WaveNet\n",
      "\n",
      "If the problem is audio synthesis:\n",
      "  If requires_realistic_sound_generation:\n",
      "    Use DL models: GAN, Variational Autoencoder (VAE)\n",
      "  Else:\n",
      "    Use DL models: WaveNet\n",
      "\n",
      "Audio Classification: ['CNN-based Models', 'K-Nearest Neighbors (KNN)']\n",
      "Warning: No suitable models found for task 'audio_classification' with characteristics ['irrelevant_characteristic'].\n",
      "Audio Classification (No match): None\n",
      "Warning: No suitable models found for task 'audio_classification' with characteristics ['unknown_condition'].\n"
     ]
    }
   ],
   "source": [
    "def validate_logic(models, condition=None):\n",
    "    \"\"\"\n",
    "    Validates if the models fit the condition.\n",
    "\n",
    "    Args:\n",
    "        models (list): List of models retrieved from the rules.\n",
    "        condition (str, optional): Specific condition being validated.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if validation passes, False otherwise.\n",
    "    \"\"\"\n",
    "    if not models:\n",
    "        print(f\"Warning: No models fit the condition '{condition}'.\")\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def handle_flat_conditions(sub_conditions, indent_level=2):\n",
    "    \"\"\"\n",
    "    Handles flat ML/DL conditions for audio tasks.\n",
    "    \"\"\"\n",
    "    logic = \"\"\n",
    "    indent = \"  \" * indent_level\n",
    "    for approach, model_list in sub_conditions.items():\n",
    "        logic += f\"{indent}Use {approach} models: {', '.join(model_list)}\\n\"\n",
    "    return logic\n",
    "\n",
    "def generate_task_logic(data, task_name):\n",
    "    \"\"\"\n",
    "    Handles logic dynamically for all audio tasks.\n",
    "    \"\"\"\n",
    "    logic_text = f\"If the problem is {task_name.replace('_', ' ')}:\\n\"\n",
    "    task_details = data[\"tasks\"][task_name]\n",
    "\n",
    "    for condition, sub_conditions in task_details.items():\n",
    "        if condition == \"default\":\n",
    "            logic_text += f\"  Else:\\n\"\n",
    "        else:\n",
    "            logic_text += f\"  If {condition}:\\n\"\n",
    "        \n",
    "        logic_text += handle_flat_conditions(sub_conditions, indent_level=2)\n",
    "\n",
    "    return logic_text\n",
    "\n",
    "def generate_audio_logic(task):\n",
    "    \"\"\"\n",
    "    Generate ML/DL decision logic dynamically for audio data tasks.\n",
    "\n",
    "    Args:\n",
    "        task (str): Task type (e.g., 'audio_classification', 'speech_recognition').\n",
    "\n",
    "    Returns:\n",
    "        str: Decision logic text.\n",
    "    \"\"\"\n",
    "    valid_tasks = audio_data_rules[\"tasks\"].keys()\n",
    "    if task not in valid_tasks:\n",
    "        raise ValueError(f\"Task '{task}' is not supported. Available tasks: {', '.join(valid_tasks)}\")\n",
    "\n",
    "    return generate_task_logic(audio_data_rules, task)\n",
    "\n",
    "# Example usage of audio logic generation\n",
    "print(generate_audio_logic(\"audio_classification\"))\n",
    "print(generate_audio_logic(\"sequential_audio_patterns\"))\n",
    "print(generate_audio_logic(\"speech_recognition\"))\n",
    "print(generate_audio_logic(\"text_to_speech_synthesis\"))\n",
    "print(generate_audio_logic(\"audio_synthesis\"))\n",
    "\n",
    "# Function to validate model choices based on dataset characteristics\n",
    "def validate_model_choice(task_rules, task_name, dataset_characteristics):\n",
    "    \"\"\"\n",
    "    Validate model choices based on dataset characteristics and task rules.\n",
    "    Raises warnings if no model fits the conditions defined in the rules.\n",
    "    \"\"\"\n",
    "    if task_name not in task_rules[\"tasks\"]:\n",
    "        raise ValueError(f\"Task '{task_name}' is not supported.\")\n",
    "\n",
    "    task_details = task_rules[\"tasks\"][task_name]\n",
    "    applicable_models = []\n",
    "\n",
    "    # Check if any condition matches the dataset characteristics\n",
    "    for condition, sub_conditions in task_details.items():\n",
    "        if condition == \"default\":\n",
    "            continue  # Default is handled later\n",
    "\n",
    "        if condition in dataset_characteristics:\n",
    "            applicable_models.extend(\n",
    "                model\n",
    "                for approach in sub_conditions.values()\n",
    "                for model in approach\n",
    "            )\n",
    "\n",
    "    # Return default models only if some valid characteristics exist but no models match\n",
    "    if not applicable_models and \"default\" in task_details:\n",
    "        # Return default models only if characteristics are valid (but no specific matches)\n",
    "        if any(cond in task_details for cond in dataset_characteristics):\n",
    "            applicable_models.extend(\n",
    "                model\n",
    "                for approach in task_details[\"default\"].values()\n",
    "                for model in approach\n",
    "            )\n",
    "\n",
    "    if not applicable_models:\n",
    "        print(f\"Warning: No suitable models found for task '{task_name}' with characteristics {dataset_characteristics}.\")\n",
    "        return None\n",
    "\n",
    "    return applicable_models\n",
    "\n",
    "# Example validation for audio data rules\n",
    "dataset_characteristics_audio = [\"requires_real_time_constraints\", \"is_proximity_based\"]\n",
    "print(\"Audio Classification:\", validate_model_choice(audio_data_rules, \"audio_classification\", dataset_characteristics_audio))\n",
    "\n",
    "dataset_characteristics_audio_empty = [\"irrelevant_characteristic\"]\n",
    "print(\"Audio Classification (No match):\", validate_model_choice(audio_data_rules, \"audio_classification\", dataset_characteristics_audio_empty))\n",
    "\n",
    "# Unit tests for audio data logic\n",
    "class TestAudioLogic(unittest.TestCase):\n",
    "    \"\"\"\n",
    "    Unit tests for the generate_audio_logic function and model validation.\n",
    "    \"\"\"\n",
    "    def test_audio_classification_logic(self):\n",
    "        \"\"\"\n",
    "        Test audio classification logic.\n",
    "        \"\"\"\n",
    "        result = generate_audio_logic(\"audio_classification\")\n",
    "        self.assertIn(\"CNN-based Models\", result, \"Expected 'CNN-based Models' in audio classification logic.\")\n",
    "\n",
    "    def test_speech_recognition_logic(self):\n",
    "        \"\"\"\n",
    "        Test speech recognition logic.\n",
    "        \"\"\"\n",
    "        result = generate_audio_logic(\"speech_recognition\")\n",
    "        self.assertIn(\"DeepSpeech\", result, \"Expected 'DeepSpeech' in speech recognition logic.\")\n",
    "\n",
    "    def test_invalid_task(self):\n",
    "        \"\"\"\n",
    "        Test behavior for an invalid task.\n",
    "        \"\"\"\n",
    "        with self.assertRaises(ValueError):\n",
    "            generate_audio_logic(\"invalid_task\")\n",
    "\n",
    "    def test_model_validation(self):\n",
    "        \"\"\"\n",
    "        Test model validation based on dataset characteristics.\n",
    "        \"\"\"\n",
    "        dataset_characteristics = [\"requires_real_time_constraints\", \"is_proximity_based\"]\n",
    "        result = validate_model_choice(audio_data_rules, \"audio_classification\", dataset_characteristics)\n",
    "        self.assertIn(\"CNN-based Models\", result, \"Expected 'CNN-based Models' in the applicable models for audio classification.\")\n",
    "        \n",
    "    def test_invalid_characteristics(self):\n",
    "        \"\"\"\n",
    "        Test model validation with invalid dataset characteristics.\n",
    "        \"\"\"\n",
    "        dataset_characteristics = [\"unknown_condition\"]\n",
    "        result = validate_model_choice(audio_data_rules, \"audio_classification\", dataset_characteristics)\n",
    "        self.assertIsNone(result, \"Expected no models to be found for unknown conditions.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    unittest.main(argv=[''], exit=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a3185e-cbb2-43f5-a58c-61fb1b10d0ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
